import json
import os
import shutil  # ëˆ„ë½ëœ import ì¶”ê°€
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List

from jinja2 import Template


def generate_enhanced_html_report(
    results_path: str, 
    eval_db_path: str,
    output_path: str = "data/reports/govscan_report.html",
    template_path: str = None,
    scan_info: Dict[str, Any] = None
) -> str:
    """
    ê°•í™”ëœ HTML ë³´ê³ ì„œ ìƒì„±
    """
    if template_path is None:
        template_path = Path(__file__).parent / "template" / "enhanced_report_template.html"

    # ë°ì´í„° ë¡œë“œ
    with open(results_path, encoding="utf-8") as f:
        results = json.load(f)

    with open(eval_db_path, encoding="utf-8") as f:
        eval_db = json.load(f)

    # ë³´ê³ ì„œ ë©”íƒ€ë°ì´í„°
    report_metadata = {
        "report_date": datetime.now().strftime("%Yë…„ %mì›” %dì¼ %Hì‹œ %Më¶„"),
        "scan_range": scan_info.get("ip_range", "ì „ì²´ ë„¤íŠ¸ì›Œí¬") if scan_info else "ì „ì²´ ë„¤íŠ¸ì›Œí¬",
        "total_hosts": 0,
        "critical_issues": 0,
        "high_issues": 0,
        "medium_issues": 0,
        "total_cves": 0
    }

    # ë³´ê³ ì„œ ë°ì´í„° ì²˜ë¦¬
    report_rows = []
    all_cves = set()
    
    for ip, policies in results.get("policy_violations", {}).items():
        # CVE ì •ë³´ ìˆ˜ì§‘
        cves = []
        if ip in results.get("vulnerabilities", {}):
            for vuln_info in results["vulnerabilities"][ip].values():
                cves.extend(vuln_info.get("cves", []))
        
        all_cves.update(cves)
        cve_summary = ", ".join(sorted(set(cves)))

        # ì§€ì ì‚¬í•­ ë° ê´€ë ¨ ì •ë³´ ìˆ˜ì§‘
        findings = []
        mitigations = []
        check_scripts = []
        checklists = []
        
        severity_score = 0
        
        for code, info in policies.items():
            rule_info = eval_db.get(code, {})
            
            # ì§€ì ì‚¬í•­
            findings.append(f"[{code}] {info['name']}")
            
            # ì¡°ì¹˜ë°©ë²•
            mitigation = rule_info.get("general_mitigation", "")
            if mitigation:
                mitigations.append(f"<strong>[{code}]</strong> {mitigation}")
            
            # ì ê²€ ìŠ¤í¬ë¦½íŠ¸ ì •ë³´
            script_name = rule_info.get("check_script", "")
            if script_name:
                check_scripts.append({
                    "name": f"{code} ì ê²€ ìŠ¤í¬ë¦½íŠ¸",
                    "filename": script_name,
                    "description": rule_info.get("name", "")
                })
            
            # ì²´í¬ë¦¬ìŠ¤íŠ¸
            checklist_items = rule_info.get("checklist_items", [])
            checklists.extend([f"[{code}] {item}" for item in checklist_items])
            
            # ì‹¬ê°ë„ ê³„ì‚°
            severity_score += calculate_severity_score(code, info)

        # ì „ì²´ ì‹¬ê°ë„ íŒì •
        if severity_score >= 15:
            severity = "critical"
            severity_text = "ì‹¬ê°"
            report_metadata["critical_issues"] += 1
        elif severity_score >= 10:
            severity = "high" 
            severity_text = "ë†’ìŒ"
            report_metadata["high_issues"] += 1
        else:
            severity = "medium"
            severity_text = "ë³´í†µ"
            report_metadata["medium_issues"] += 1

        report_rows.append({
            "host": ip,
            "role": get_host_role(ip),  # IPë¡œë¶€í„° ì—­í•  ì¶”ì •
            "issues": findings,
            "cves": cve_summary,
            "mitigation": "<br><br>".join(mitigations),
            "check_scripts": check_scripts,
            "checklists": checklists,
            "severity": severity,
            "severity_text": severity_text
        })

    # ë©”íƒ€ë°ì´í„° ì™„ì„±
    report_metadata["total_hosts"] = len(report_rows)
    report_metadata["total_cves"] = len(all_cves)

    # í…œí”Œë¦¿ ë Œë”ë§
    with open(template_path, encoding="utf-8") as tpl:
        template = Template(tpl.read())

    html = template.render(
        rows=report_rows,
        **report_metadata
    )

    # ì¶œë ¥ ê²½ë¡œ ìƒì„± ë° ì €ì¥
    output_file = Path(output_path)
    output_file.parent.mkdir(parents=True, exist_ok=True)
    output_file.write_text(html, encoding="utf-8")

    print(f"âœ… ê°•í™”ëœ HTML ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ â†’ {output_path}")
    return str(output_file.absolute())


def calculate_severity_score(rule_code: str, violation_info: Dict[str, Any]) -> int:
    """
    ìœ„ë°˜ ì‚¬í•­ì˜ ì‹¬ê°ë„ ì ìˆ˜ ê³„ì‚°
    """
    severity_map = {
        # ì ‘ê·¼í†µì œ ê´€ë ¨ - ë†’ì€ ìœ„í—˜
        "20501": 5,  # ì ‘ê·¼í†µì œ ë¯¸í¡
        "20502": 4,  # SSH ì•½í•œ ì¸ì¦
        "20503": 4,  # ì·¨ì•½í•œ ì„œë¹„ìŠ¤
        
        # ì •ë³´ë…¸ì¶œ ê´€ë ¨ - ì¤‘ê°„ ìœ„í—˜
        "30802": 3,  # ë²„ì „ì •ë³´ ë…¸ì¶œ
        "30701": 3,  # ì›¹ ì„œë²„ ë³´ì•ˆ
        
        # ê´€ë¦¬ ê´€ë ¨ - ë‚®ì€-ì¤‘ê°„ ìœ„í—˜
        "11303": 2,  # ê´€ë¦¬ëŒ€ì¥ ëˆ„ë½
        "30301": 2,  # ë„¤íŠ¸ì›Œí¬ ê´€ë¦¬ëŒ€ì¥
        "30501": 2,  # ë¶ˆí•„ìš”í•œ ì„œë¹„ìŠ¤
        "30601": 3,  # SNMP ë³´ì•ˆ
        "40101": 4,  # íŒ¨ì¹˜ ê´€ë¦¬
    }
    
    base_score = severity_map.get(rule_code, 2)
    violation_count = len(violation_info.get("violations", []))
    
    return base_score + min(violation_count, 3)  # ìµœëŒ€ 3ì  ì¶”ê°€


def get_host_role(ip: str) -> str:
    """
    IP ì£¼ì†Œë¡œë¶€í„° í˜¸ìŠ¤íŠ¸ ì—­í•  ì¶”ì •
    """
    # ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹± - ì‹¤ì œë¡œëŠ” ê´€ë¦¬ëŒ€ì¥ì—ì„œ ê°€ì ¸ì™€ì•¼ í•¨
    octets = ip.split('.')
    if len(octets) == 4:
        last_octet = int(octets[3])
        if last_octet == 1:
            return "ê²Œì´íŠ¸ì›¨ì´/ë¼ìš°í„°"
        elif last_octet < 10:
            return "ì„œë²„"
        elif last_octet > 100:
            return "í´ë¼ì´ì–¸íŠ¸"
        else:
            return "ì„œë²„/ì¥ë¹„"
    return "ë¯¸ì§€ì •"


def generate_scripts_archive(eval_db_path: str, output_dir: str = "data/reports/scripts") -> str:
    """
    ì ê²€ ìŠ¤í¬ë¦½íŠ¸ë“¤ì„ ì•„ì¹´ì´ë¸Œë¡œ ìƒì„±
    """
    # script_generator ëª¨ë“ˆ import ìˆ˜ì •
    try:
        from backend.report.script_generator import generate_check_scripts
    except ImportError:
        from .script_generator import generate_check_scripts
    
    import zipfile

    # ìŠ¤í¬ë¦½íŠ¸ ìƒì„±
    scripts_dir = Path(output_dir) / "generated"
    scripts_dir.mkdir(parents=True, exist_ok=True)
    
    generate_check_scripts(eval_db_path, str(scripts_dir))
    
    # ZIP ì•„ì¹´ì´ë¸Œ ìƒì„±
    archive_path = Path(output_dir) / "check_scripts.zip"
    with zipfile.ZipFile(archive_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
        for script_file in scripts_dir.glob("*.sh"):
            zipf.write(script_file, script_file.name)
    
    print(f"âœ… ì ê²€ ìŠ¤í¬ë¦½íŠ¸ ì•„ì¹´ì´ë¸Œ ìƒì„± ì™„ë£Œ â†’ {archive_path}")
    return str(archive_path)


def create_checklist_document(eval_db_path: str, output_path: str = "data/reports/checklist.txt") -> str:
    """
    í†µí•© ì²´í¬ë¦¬ìŠ¤íŠ¸ ë¬¸ì„œ ìƒì„±
    """
    with open(eval_db_path, 'r', encoding='utf-8') as f:
        eval_db = json.load(f)
    
    checklist_content = []
    checklist_content.append("=" * 60)
    checklist_content.append("GovScan ë³´ì•ˆì ê²€ ì²´í¬ë¦¬ìŠ¤íŠ¸")
    checklist_content.append("=" * 60)
    checklist_content.append(f"ìƒì„±ì¼ì‹œ: {datetime.now().strftime('%Yë…„ %mì›” %dì¼ %Hì‹œ %Më¶„')}")
    checklist_content.append("")
    
    for rule_code, rule_info in sorted(eval_db.items()):
        checklist_content.append(f"[{rule_code}] {rule_info.get('name', '')}")
        checklist_content.append("-" * 50)
        checklist_content.append(f"ì„¤ëª…: {rule_info.get('description', '')}")
        checklist_content.append("")
        
        checklist_items = rule_info.get('checklist_items', [])
        for i, item in enumerate(checklist_items, 1):
            checklist_content.append(f"  â–¡ {i}. {item}")
        
        checklist_content.append("")
        checklist_content.append(f"ì¡°ì¹˜ë°©ë²•: {rule_info.get('general_mitigation', '')}")
        checklist_content.append("")
        checklist_content.append("")
    
    # íŒŒì¼ ì €ì¥
    output_file = Path(output_path)
    output_file.parent.mkdir(parents=True, exist_ok=True)
    output_file.write_text('\n'.join(checklist_content), encoding='utf-8')
    
    print(f"âœ… ì²´í¬ë¦¬ìŠ¤íŠ¸ ë¬¸ì„œ ìƒì„± ì™„ë£Œ â†’ {output_path}")
    return str(output_file.absolute())


def generate_comprehensive_report(
    results_path: str,
    eval_db_path: str, 
    output_dir: str = "data/reports",
    scan_info: Dict[str, Any] = None
) -> Dict[str, str]:
    """
    ì¢…í•© ë³´ê³ ì„œ íŒ¨í‚¤ì§€ ìƒì„± (HTML + ìŠ¤í¬ë¦½íŠ¸ + ì²´í¬ë¦¬ìŠ¤íŠ¸)
    """
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # 1. HTML ë³´ê³ ì„œ ìƒì„±
    html_report = generate_enhanced_html_report(
        results_path=results_path,
        eval_db_path=eval_db_path,
        output_path=str(output_path / f"govscan_report_{timestamp}.html"),
        scan_info=scan_info
    )
    
    # 2. ì ê²€ ìŠ¤í¬ë¦½íŠ¸ ì•„ì¹´ì´ë¸Œ ìƒì„±
    scripts_archive = generate_scripts_archive(
        eval_db_path=eval_db_path,
        output_dir=str(output_path / "scripts")
    )
    
    # 3. ì²´í¬ë¦¬ìŠ¤íŠ¸ ë¬¸ì„œ ìƒì„±
    checklist_doc = create_checklist_document(
        eval_db_path=eval_db_path,
        output_path=str(output_path / f"checklist_{timestamp}.txt")
    )
    
    # 4. JSON ê²°ê³¼ ë³µì‚¬ (ì°¸ì¡°ìš©)
    json_result = output_path / f"analysis_results_{timestamp}.json"
    shutil.copy2(results_path, json_result)
    
    report_package = {
        "html_report": html_report,
        "scripts_archive": scripts_archive,
        "checklist_document": checklist_doc,
        "json_results": str(json_result),
        "timestamp": timestamp
    }
    
    # íŒ¨í‚¤ì§€ ì •ë³´ ì €ì¥
    package_info = output_path / f"report_package_{timestamp}.json"
    with open(package_info, 'w', encoding='utf-8') as f:
        json.dump(report_package, f, indent=2, ensure_ascii=False)
    
    print(f"âœ… ì¢…í•© ë³´ê³ ì„œ íŒ¨í‚¤ì§€ ìƒì„± ì™„ë£Œ:")
    print(f"   ğŸ“„ HTML ë³´ê³ ì„œ: {html_report}")
    print(f"   ğŸ“¦ ì ê²€ ìŠ¤í¬ë¦½íŠ¸: {scripts_archive}")
    print(f"   ğŸ“‹ ì²´í¬ë¦¬ìŠ¤íŠ¸: {checklist_doc}")
    print(f"   ğŸ“Š JSON ê²°ê³¼: {json_result}")
    
    return report_package


# CLI ì‹¤í–‰ì„ ìœ„í•œ ë©”ì¸ í•¨ìˆ˜
if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="ğŸ“Š GovScan ê°•í™”ëœ ë³´ê³ ì„œ ìƒì„±ê¸°")
    parser.add_argument("-r", "--results", default="data/reports/analysis_results.json", 
                       help="ë¶„ì„ ê²°ê³¼ JSON íŒŒì¼")
    parser.add_argument("-e", "--eval", default="data/db/eval_db.json", 
                       help="í‰ê°€ ê¸°ì¤€ JSON íŒŒì¼")
    parser.add_argument("-o", "--output", default="data/reports", 
                       help="ì¶œë ¥ ë””ë ‰í† ë¦¬")
    parser.add_argument("--comprehensive", action="store_true", 
                       help="ì¢…í•© ë³´ê³ ì„œ íŒ¨í‚¤ì§€ ìƒì„±")
    parser.add_argument("--scan-range", default="ì „ì²´ ë„¤íŠ¸ì›Œí¬", 
                       help="ìŠ¤ìº” ë²”ìœ„ ì„¤ëª…")
    
    args = parser.parse_args()
    
    scan_info = {
        "ip_range": args.scan_range,
        "scan_date": datetime.now().isoformat()
    }
    
    if args.comprehensive:
        generate_comprehensive_report(
            results_path=args.results,
            eval_db_path=args.eval,
            output_dir=args.output,
            scan_info=scan_info
        )
    else:
        generate_enhanced_html_report(
            results_path=args.results,
            eval_db_path=args.eval,
            output_path=os.path.join(args.output, "govscan_report.html"),
            scan_info=scan_info
        )